[2025-06-12T15:27:51.163+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deep_models_pipeline.predict_best_model manual__2025-06-12T15:25:43.291090+00:00 [queued]>
[2025-06-12T15:27:51.169+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deep_models_pipeline.predict_best_model manual__2025-06-12T15:25:43.291090+00:00 [queued]>
[2025-06-12T15:27:51.170+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 3
[2025-06-12T15:27:51.179+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): predict_best_model> on 2025-06-12 15:25:43.291090+00:00
[2025-06-12T15:27:51.185+0000] {standard_task_runner.py:60} INFO - Started process 641 to run task
[2025-06-12T15:27:51.187+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'deep_models_pipeline', 'predict_best_model', 'manual__2025-06-12T15:25:43.291090+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/train_deep_model_dag.py', '--cfg-path', '/tmp/tmppbeuam8p']
[2025-06-12T15:27:51.188+0000] {standard_task_runner.py:88} INFO - Job 40: Subtask predict_best_model
[2025-06-12T15:27:51.219+0000] {task_command.py:423} INFO - Running <TaskInstance: deep_models_pipeline.predict_best_model manual__2025-06-12T15:25:43.291090+00:00 [running]> on host e25078c6d813
[2025-06-12T15:27:51.271+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deep_models_pipeline' AIRFLOW_CTX_TASK_ID='predict_best_model' AIRFLOW_CTX_EXECUTION_DATE='2025-06-12T15:25:43.291090+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-12T15:25:43.291090+00:00'
[2025-06-12T15:27:51.272+0000] {train_deep_model_dag.py:13} INFO - 🟦 Running command: python /opt/***/src/models/predict_best_model.py
[2025-06-12T15:32:24.957+0000] {train_deep_model_dag.py:20} INFO - 🟩 [stdout]:
   user_id                                    recommendations
0        1  [0, 4331, 2064, 2769, 5445, 7994, 9847, 9070, ...
1        2  [1, 1790, 2138, 8359, 1591, 5551, 2805, 7680, ...
2        3  [2, 407, 390, 1886, 4, 3042, 6098, 1584, 5155,...
3        4  [3, 1889, 4651, 1379, 1207, 8642, 1627, 45, 93...
4        5  [4, 5834, 2, 7635, 7232, 1497, 5049, 173, 834,...

[2025-06-12T15:32:24.959+0000] {train_deep_model_dag.py:22} WARNING - 🟨 [stderr]:
2025-06-12 15:27:53,198 - INFO - 🚀 Starte Prediction für hybrid_deep_model über MLflow Registry

Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]
Downloading artifacts:  12%|█▎        | 1/8 [00:00<00:00, 14768.68it/s]
Downloading artifacts:  25%|██▌       | 2/8 [00:00<00:02,  2.12it/s]   
Downloading artifacts:  25%|██▌       | 2/8 [00:00<00:02,  2.12it/s]
Downloading artifacts:  38%|███▊      | 3/8 [00:02<00:04,  1.17it/s]
Downloading artifacts:  38%|███▊      | 3/8 [00:02<00:04,  1.17it/s]
Downloading artifacts:  50%|█████     | 4/8 [00:03<00:03,  1.19it/s]
Downloading artifacts:  50%|█████     | 4/8 [00:03<00:03,  1.19it/s]
Downloading artifacts:  62%|██████▎   | 5/8 [00:03<00:02,  1.19it/s]
Downloading artifacts:  62%|██████▎   | 5/8 [00:03<00:02,  1.19it/s]
Downloading artifacts:  75%|███████▌  | 6/8 [00:04<00:01,  1.14it/s]
Downloading artifacts:  75%|███████▌  | 6/8 [00:04<00:01,  1.14it/s]
Downloading artifacts:  88%|████████▊ | 7/8 [00:05<00:00,  1.09it/s]
Downloading artifacts:  88%|████████▊ | 7/8 [00:05<00:00,  1.09it/s]
Downloading artifacts: 100%|██████████| 8/8 [00:06<00:00,  1.05it/s]
Downloading artifacts: 100%|██████████| 8/8 [00:06<00:00,  1.05it/s]
Downloading artifacts: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]

Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]
Downloading artifacts: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]
Downloading artifacts: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]
Downloading artifacts: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]
2025-06-12 15:28:11,669 - INFO - 📥 Embedding geladen (direkt aus Registry): Shape: (10381, 32)

Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]
Downloading artifacts:   0%|          | 0/1 [04:10<?, ?it/s]
2025-06-12 15:32:24,212 - WARNING - ⚠️ Konnte pipeline_conf.json nicht laden: The following failures occurred while downloading one or more artifacts from https://dagshub.com/sacer11/MLOps_movie_rec_apr25.mlflow/api/2.0/mlflow-artifacts/artifacts/2b8041adbf9f473d9fa511b906124b0e/a4e31967694e43e6971c4967466b5f5e/artifacts:
##### File best_config/pipeline_conf_best.json #####
API request to https://dagshub.com/sacer11/MLOps_movie_rec_apr25.mlflow/api/2.0/mlflow-artifacts/artifacts/2b8041adbf9f473d9fa511b906124b0e/a4e31967694e43e6971c4967466b5f5e/artifacts/best_config/pipeline_conf_best.json failed with exception HTTPSConnectionPool(host='dagshub.com', port=443): Max retries exceeded with url: /sacer11/MLOps_movie_rec_apr25.mlflow/api/2.0/mlflow-artifacts/artifacts/2b8041adbf9f473d9fa511b906124b0e/a4e31967694e43e6971c4967466b5f5e/artifacts/best_config/pipeline_conf_best.json (Caused by ResponseError('too many 500 error responses'))
2025-06-12 15:32:24,372 - INFO - ✅ Prediction erfolgreich – keine Speicherung auf Disk, nur im RAM.

[2025-06-12T15:32:24.960+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-06-12T15:32:24.976+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=deep_models_pipeline, task_id=predict_best_model, execution_date=20250612T152543, start_date=20250612T152751, end_date=20250612T153224
[2025-06-12T15:32:25.030+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-06-12T15:32:25.046+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check

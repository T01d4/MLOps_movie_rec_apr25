# ✅ version entfernt – Compose V2 benötigt das nicht mehr
# docker-compose.yml – für DagsHub-only MLflow-Tracking

services:

  streamlit:
    build:
      context: ./streamlit_app
      dockerfile: Dockerfile.streamlit
    container_name: streamlit_app
    ports:
      - "8501:8501"
    volumes:
      - ./data:/app/data
      - ./models:/app/models      # Modelle (optional, z. B. für local serving)
      - ./src:/app/src            # Trainingscode
      - ./.dvc:/app/.dvc           # <--- KORREKT!
      - ./.git:/app/.git           # <--- KORREKT!
    env_file: .env

    networks:
      - airflow_net

  api:
    build:
      context: ./api_service
    container_name: api_service
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
    env_file: .env
    networks:
      - airflow_net

  # MLflow-Service wird **NICHT** benötigt – du nutzt DagsHub als Remote Registry!

  postgres:
    image: postgres:13
    container_name: postgres_airflow
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_db:/var/lib/postgresql/data
    networks:
      - airflow_net

  airflow-webserver:
    build:
      context: .
      dockerfile: airflow/Dockerfile.airflow
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    working_dir: /opt/airflow
    env_file: .env
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW_UID=50000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/logs:/opt/airflow/logs
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./models:/opt/airflow/models
      - ./.dvc:/opt/airflow/.dvc           # <--- das hinzufügen!
      - ./.git:/opt/airflow/.git             # <-- NEU!

    command: >
      bash -c "
        airflow db upgrade &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
        airflow webserver
      "
    networks:
      - airflow_net

  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow/Dockerfile.airflow
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
    working_dir: /opt/airflow
    env_file: .env
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW_UID=50000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/logs:/opt/airflow/logs
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./models:/opt/airflow/models
      - ./.dvc:/opt/airflow/.dvc           # <--- das hinzufügen!
      - ./.git:/opt/airflow/.git             # <-- NEU

    command: airflow scheduler
    networks:
      - airflow_net

volumes:
  postgres_db:

networks:
  airflow_net: {}
